# Техническое видение проекта xyliganimbot

*Документ описывает техническое видение проекта для проверки идеи поиска ответов в базе знаний через Telegram-бота.*

## Технологии

Для первого релиза выбран максимально простой стек, позволяющий быстро проверить идею без оверинжиниринга.

- **Бэкенд**: Python 3.x с минимальным набором зависимостей.
- **Telegram-бот**: библиотека `python-telegram-bot` (или `aiogram`) с использованием long polling для получения обновлений.
- **Работа с Google Docs**: доступ к текстовому документу через Google Docs API или экспорт документа в текстовый формат по прямой ссылке. Для работы с API используется библиотека `google-api-python-client` с аутентификацией через сервисный аккаунт или OAuth.
- **Поиск**: семантический поиск через embedding-модели (библиотека `sentence-transformers`) для понимания смысла запросов. Используется мультиязычная модель `paraphrase-multilingual-MiniLM-L12-v2` или `multilingual-e5-small` для работы с русским и английским текстом. Модели хранятся локально для автономной работы без интернета. LLM для генерации ответов планируется добавить в последующих версиях.
- **Кэширование**: опциональное кэширование содержимого документа в JSON-файле с проверкой даты последнего обновления документа. Так как документ обновляется редко и имеет небольшой размер, допустимо запрашивать актуальную версию при каждом запросе или обновлять кэш при изменении документа.
- **Инфраструктура**: один Docker-контейнер, развертывание в кластере Kubernetes на трех VM с Ubuntu (на ноутбуке).

## Принцип разработки

Разработка ведётся с приоритетом простоты и быстрой проверки идеи.

- **KISS (Keep It Simple, Stupid)**: максимально простое решение без лишних абстракций и оверинжиниринга. Только самое необходимое для проверки идеи.
- **MVP-first**: реализуется только необходимый минимум для проверки идеи.
- **Файловое хранилище**: без БД на первом этапе, все данные хранятся в файлах (Markdown, JSON).
- **Допустима потеря состояния**: при перезапуске состояние не сохраняется, бот работает stateless.
- **Один чат, ограниченное число пользователей**: бот предназначен для работы в одном групповом чате с ограниченным числом пользователей.
- **Без преждевременной оптимизации**: приоритет простым решениям, оптимизация только при реальной необходимости.
- **Embedding-модели для семантического поиска**: используются для понимания смысла запросов, являются частью MVP. Модели хранятся локально для автономной работы.
- **LLM — опционально**: подключается только при явной пользе, не является частью MVP.
- **Маленькие инкрементальные шаги**: функциональность добавляется небольшими шагами, сначала базовый поиск, затем улучшения.
- **Ручное тестирование**: основной упор на тестирование через Telegram-бота. Автоматические тесты на первом этапе не требуются.
- **Простая документация**: README с инструкцией по запуску (включая команды для выполнения через SSH) и простой список команд бота. ADR создаются по необходимости для фиксации ключевых архитектурных решений.
- **Кодстайл**: код пишется с приоритетом читаемости, форматирование совместимо с `black`.

## Структура проекта

Структура проекта ориентирована на простоту и понятность расположения кода, данных и документации.

```
xyliganimbot/
├── src/              # Исходный код бота
│   ├── bot.py        # Основной модуль бота
│   ├── handlers/     # Обработчики команд и сообщений
│   ├── google_docs.py # Работа с Google Docs
│   └── search.py     # Логика поиска
├── data/             # Кэш документа (опционально)
├── models/            # Локальное хранилище embedding-моделей
├── logs/             # Логи приложения
├── docs/             # Документация
├── k8s/              # Kubernetes манифесты
├── tests/            # Тесты (на будущее)
├── Dockerfile        # Образ для контейнера
├── requirements.txt  # Зависимости Python
├── config.yaml       # Конфигурация (без секретов)
├── .env.example      # Пример переменных окружения
└── README.md         # Инструкции по запуску
```

- **Код приложения**: в каталоге `src/` размещается исходный код бота, обработчики команд и модули для работы с Google Docs и поиском.
- **Данные**: в каталоге `data/` хранится документ базы знаний (`data/knowledge.md`), JSON-файл с метаданными (`data/knowledge_cache.json`), а также папка `data/images/` для локального хранения изображений из документа.
- **Модели**: в каталоге `models/` хранятся embedding-модели для семантического поиска. Модели загружаются администратором вручную (через команду или скрипт) и сохраняются локально в папке `models/` для автономной работы без интернета. При запуске бота модели не загружаются автоматически.
- **Логи**: в каталоге `logs/` сохраняются логи приложения и журнал действий.
- **Документация**: в каталоге `docs/` размещаются основные документы проекта (`idea.md`, `vision.md`), ADR создаются по необходимости.
- **Конфигурация**: для конфигурации используется файл `config.yaml` в корне проекта. Секретные значения (токен Telegram-бота, учетные данные Google API) передаются через переменные окружения.
- **Контейнеризация и оркестрация**: в корне проекта располагается `Dockerfile` для сборки образа. В каталоге `k8s/` размещаются манифесты Kubernetes для развертывания в кластере.

## Архитектура проекта

Архитектура строится вокруг одного простого сервиса Telegram-бота с разделением на три логических слоя.

- **Слой интеграции с Telegram**: тонкий слой, отвечающий за приём обновлений через long polling, разбор входящих сообщений и маршрутизацию к обработчикам. Здесь не содержится бизнес-логика, только адаптация данных Telegram к внутренним моделям. На этом уровне выполняется проверка белого списка пользователей/чатов.
- **Доменный слой (логика поиска)**: отдельный модуль, в котором реализуются сценарии работы — обработка команд (например, `/help`, `/search`) и обработка всех сообщений как запросов к базе знаний. Этот слой оперирует абстракциями «запрос», «документ», «результат поиска» и обращается к модулю доступа к данным.
- **Слой доступа к данным**: модуль, инкапсулирующий работу с Google Docs API, получение содержимого документа и кэширование. Telegram-слой не знает о деталях работы с Google.

**Принципы:**
- **Один процесс/сервис**: весь функционал разворачивается как один процесс/контейнер.
- **Обработка запросов по требованию**: все действия выполняются по запросу пользователя (команды или сообщения), без фоновых задач на первом этапе.
- **Идентификация пользователей**: при обработке запросов фиксируются идентификатор и имя пользователя из Telegram для логирования и проверки доступа.

## Модель данных

Модель данных первого релиза минималистична и ориентирована на простоту.

- **База знаний**: в `data/knowledge.md`. Работа с изображениями будет добавлена позже.

- **Заголовки разделов**: разделы документа определяются автоматически по форматированию Markdown (заголовки уровня 2 и выше, например `## 7. Название раздела`).

- **Кэш документа** (опционально): JSON-файл в `data/knowledge_cache.json` с полями:
  - `content`: текст документа (или путь к HTML/Markdown файлу)
  - `last_updated`: дата/время последнего обновления документа в Google Docs
  - `document_id`: идентификатор документа для проверки изменений
  - `images`: массив путей к локальным файлам изображений в папке `data/images/` (опционально)
  - `embeddings`: опционально — векторы разделов для семантического поиска (хранятся в памяти при работе, могут быть сериализованы для ускорения загрузки)

- **Журнал действий**: текстовый файл `logs/audit.log` с записями о каждой операции:
  - дата и время
  - `telegram_id`, `username` (если доступен)
  - запрос пользователя (команда или текст сообщения)
  - результат (найдено/не найдено, количество результатов, ошибки)

**Идеи на будущее:**
- История запросов пользователей (опционально, по дополнительной настройке)
- Статистика использования (популярные запросы, частота обращений)
- Добавление изображений в ответе

## Работа с embedding-моделями и LLM

На первом этапе используется семантический поиск через embedding-модели (не LLM). Embedding-модели преобразуют текст в числовые векторы, что позволяет находить релевантные разделы по смыслу, а не только по ключевым словам.

- **Использование моделей**: при работе бот загружает модель из локальной папки `models/` в память только при необходимости (при векторизации или поиске). Если модель не найдена локально, используется fallback на token-based поиск.
- **Производительность**: для небольшого объема данных (20-30 разделов, ~6000 слов) весь индекс помещается в оперативную память, поиск выполняется за миллисекунды.

**Планируется в будущем:**
- Использование LLM для улучшения формулировок ответов
- Генерация более развернутых ответов на основе найденной информации в документе
- Комбинирование семантического поиска с LLM для более точных и контекстных ответов

## Загрузка контента базы знаний

Контент базы знаний загружается из внешних источников и сохраняется локально. Архитектура разделена на три независимых процесса: загрузка контента, загрузка модели, векторизация контента.

### 1. Загрузка контента

Загрузка контента выполняется администратором вручную и не зависит от загрузки модели или векторизации. Импорт выполняется **отдельным скриптом вне Telegram-бота** (например, `python testing/test_import_content.py`), а не командами бота.

- **Источники контента**: на первом этапе используется Google Docs. В будущем могут быть добавлены другие источники (Markdown-файлы, веб-страницы, API и т.д.). Архитектура позволяет легко добавлять новые источники без изменения логики векторизации.
- **Хранение**: документ хранится в `data/knowledge.md`. Изображения — в `data/images/`. Метаданные (пути к изображениям, дата обновления, document_id) сохраняются в `data/knowledge_cache.json`.
- **Обработка ошибок**: при ошибке доступа к документу ошибка логируется, скрипт возвращает понятное сообщение. При недоступности документа используется существующая локальная версия, если она есть.

### 2. Загрузка embedding-модели

Загрузка модели выполняется администратором вручную и не зависит от загрузки контента или векторизации.

- **Модели**: используются мультиязычные модели (`paraphrase-multilingual-MiniLM-L12-v2` или `multilingual-e5-small`) для векторизации текста разделов и запросов пользователей.
- **Загрузка модели**: выполняется администратором вручную через команду `/admin load_model` или отдельный скрипт. Модель загружается из HuggingFace (если доступен интернет) и сохраняется локально в папке `models/` для автономной работы без интернета (важно для работы в РФ-сегменте). При запуске бота модели не загружаются автоматически.
- **Хранение**: модели хранятся локально в папке `models/` с именем модели в качестве подпапки (например, `models/paraphrase-multilingual-MiniLM-L12-v2/`).
- **Использование**: при работе бот загружает модель из локальной папки `models/` в память только при необходимости (при векторизации или поиске). Если модель не найдена локально, используется fallback на token-based поиск.

### 3. Векторизация контента

Векторизация выполняется администратором вручную после загрузки контента и модели. Это отдельный процесс, который не зависит от источника контента.

- **Векторизация разделов**: выполняется администратором вручную через команду `/admin vectorize` или отдельный скрипт. Процесс векторизации:
  1. Загружает документ из `data/knowledge.md` и извлекает заголовки разделов автоматически по форматированию Markdown
  2. Разбивает документ на разделы по заголовкам
  3. Загружает embedding-модель из папки `models/`
  4. Векторизует каждый раздел через embedding-модель (комбинация заголовка и текста: "Заголовок. Текст раздела")
  5. Сохраняет векторы в кэш (`data/knowledge_cache.json`) в формате JSON (список списков)
  6. Сохраняет связь изображений с разделами в кэш
- **Формат данных**: каждый раздел представляется как вектор фиксированной размерности (например, 384 для `paraphrase-multilingual-MiniLM-L12-v2`). Векторы хранятся в кэше в формате JSON (список списков) и загружаются в память при работе бота.
- **Независимость от источника**: процесс векторизации работает с локальными файлами (`data/knowledge.md`) и не зависит от источника контента (Google Docs, Markdown, API и т.д.). Это позволяет легко добавлять новые источники контента без изменения логики векторизации.
- **При запуске бота**: векторизация не выполняется автоматически — бот только проверяет наличие готовых embeddings в кэше.

### Проверки при работе

При обработке поисковых запросов бот проверяет наличие необходимых данных:
- наличие embedding-модели в папке `models/` (или доступность библиотеки `sentence-transformers` для fallback на token-based поиск)
- наличие документа в `data/knowledge.md`
- наличие кэша с embeddings в `data/knowledge_cache.json` (проверка, что документ индексирован и ембедизирован)

При отсутствии необходимых данных бот возвращает понятное сообщение пользователю и логирует предупреждение.

## Поисковая система

Поиск по базе знаний реализован с использованием семантического поиска через embedding-модели для понимания смысла запросов, а не только ключевых слов.

- **Векторизация разделов**: выполняется администратором вручную через команду `/admin vectorize` после загрузки контента и модели. Разделы векторизуются через embedding-модель и сохраняются в кэше. Каждый раздел представляется как вектор фиксированной размерности (например, 384 для `paraphrase-multilingual-MiniLM-L12-v2`). Векторы хранятся в кэше в формате JSON (список списков) и загружаются в память при работе бота. При запуске бота векторизация не выполняется автоматически.
- **Разделение на разделы**: разделение документа на разделы происходит автоматически при парсинге Markdown-документа по форматированию заголовков (например, `## 7. Название раздела`). Для векторизации используется комбинация заголовка и текста раздела (например, "Заголовок. Текст раздела") для лучшего понимания контекста.
- **Семантический поиск**: при запросе пользователя:
  1. Запрос векторизуется через ту же embedding-модель
  2. Вычисляется косинусное сходство между вектором запроса и всеми векторами разделов
  3. Результаты сортируются по убыванию сходства (score от 0 до 1)
  4. Возвращаются топ-N наиболее релевантных разделов (например, топ-3)
- **Ранжирование результатов**: результаты ранжируются по косинусному сходству. Если score первого результата слишком низкий (например, < 0.3), можно показать сообщение "Я не уверен, но вот что нашел..." для индикации низкой уверенности.
- **Формат возвращаемых данных**: для каждого найденного раздела возвращается цитата (фрагмент текста). Поскольку разделы небольшие (в среднем ~300 слов), для MVP используется простой подход:
  - Если раздел небольшой (например, < 500 символов), возвращается весь текст раздела
  - Если раздел большой, возвращается snippet — первые N символов (например, 200-300 символов) с указанием заголовка раздела
  - В будущем можно улучшить: подсвечивать конкретное место в разделе, которое наиболее релевантно запросу (например, через анализ подобия фраз)
- **Преимущества семантического поиска**: 
  - Понимание синонимов и разных формулировок (например, "упал сервер" и "server down" будут найдены как релевантные)
  - Работа с IT-терминами и смешением языков
  - Поиск по смыслу, а не только по точным совпадениям слов
- **Производительность**: для небольшого объема данных (20-30 разделов) весь индекс помещается в оперативную память (несколько килобайт), поиск выполняется за миллисекунды без необходимости в базе данных.

## Сценарии работы (MVP)

Сценарии работы первого релиза фокусируются на поиске ответов в базе знаний.

- **Поиск в базе знаний**:
  - Пользователь отправляет сообщение (текст запроса) или обращается к боту в чате
  - Все сообщения (кроме команд) обрабатываются как запросы к базе знаний
  - Бот выполняет семантический поиск по документу (векторизация запроса и поиск наиболее похожих разделов)
  - Бот возвращает найденные разделы с цитатами (фрагментами текста):
    - Для небольших разделов (< 500 символов) возвращается весь текст раздела
    - Для больших разделов возвращается snippet (первые 200-300 символов) с указанием заголовка
    - Каждый результат включает заголовок раздела и релевантный фрагмент текста
  - Если ничего не найдено, возвращается сообщение "не найдено"
  - Если score первого результата слишком низкий, может быть показано предупреждение о низкой уверенности
  - Если в найденном разделе есть изображения, они отправляются отдельными сообщениями после текстового ответа
  - Ответ отправляется в чат или как ответ на сообщение пользователя
  - Формат ответа: простой текст с цитатами, без форматирования (для MVP)

- **Команды**:
  - `/help` — список доступных команд и краткое описание работы бота
  - Админские команды (только для пользователей из белого списка админов):
    - `/admin load_model` — загрузка embedding-модели из HuggingFace в папку `models/` (выполняется один раз при настройке)
    - `/admin vectorize` — векторизация загруженного контента через embedding-модель и сохранение в кэш
  - Импорт контента из Google Docs выполняется отдельным скриптом вне бота (например, `python testing/test_import_content.py`), а не командой в Telegram.

- **Ограничения и неподдерживаемые сценарии**:
  - Бот не ведёт диалог — каждый запрос обрабатывается независимо
  - Бот не запоминает контекст предыдущих сообщений
  - Бот не отвечает в личных сообщениях — работает только в групповых чатах из белого списка

## Деплой

Развертывание выполняется в кластере Kubernetes на трех VM с Ubuntu.

- **Docker-образ**: сборка образа из `Dockerfile`, публикация в registry (опционально, можно использовать локальный образ).
- **Kubernetes**: развертывание через манифесты в `k8s/`:
  - Deployment — основной под с ботом
  - Service — для внутреннего доступа (если потребуется)
  - ConfigMap — для конфигурации
  - Secret — для секретных данных (токен бота, учетные данные Google API)
  - PersistentVolume и PersistentVolumeClaim — для хранения логов и кэша документа
  - Namespace — отдельный namespace для изоляции приложения
- **Инструкции**: команды для выполнения через SSH на узлах кластера:
  - Создание namespace (`kubectl create namespace xyliganimbot`)
  - Применение манифестов (`kubectl apply -f k8s/`)
  - Проверка статуса (`kubectl get pods -n xyliganimbot`, `kubectl logs -n xyliganimbot`)
  - Обновление образа (`kubectl rollout restart deployment -n xyliganimbot`)
- **Конфигурация**: секретные данные через Kubernetes Secret, остальная конфигурация через ConfigMap или переменные окружения в Deployment.

## Подход к конфигурированию

Конфигурация выносится в отдельный файл и переменные окружения для простоты управления.

- **Конфигурационный файл** (`config.yaml`): основные параметры:
  - ссылка на Google Docs
  - белый список пользователей/чатов (`telegram_id`, `chat_id`)
  - белый список админов (`telegram_id`)
  - настройки логирования (уровень, путь к файлу логов)

- **Переменные окружения**: секретные данные:
  - `TELEGRAM_BOT_TOKEN` — токен Telegram-бота
  - `GOOGLE_SERVICE_ACCOUNT_KEY` — JSON-ключ сервисного аккаунта (если используется API)
  - другие секреты

- **Kubernetes**: ConfigMap для `config.yaml`, Secret для переменных окружения

**На начальном этапе** настройки поиска (количество результатов, минимальный score для уверенности) и форматирования ответов не требуются — используется семантический поиск и простой текст в ответах.

## Подход к логгированию

Логирование в первом релизе направлено на простую диагностику и понимание поведения бота.

- **Стандартный Python logging**: используется встроенный модуль `logging` без внешних библиотек.
- **Вывод логов**: запись в файл `logs/app.log` для продакшена; опционально также в консоль (`stdout`) для локальной разработки.
- **Уровни логирования**: используются уровни DEBUG, INFO, WARNING, ERROR. Уровень логирования задаётся через конфигурацию (переменная окружения `LOG_LEVEL`).
- **Формат**: время, модуль, уровень, сообщение — простой текстовый формат, удобный для чтения человеком.
- **Ротация логов**: ротация по размеру файла (например, при достижении 10MB создаётся новый файл, старые сохраняются с суффиксом номера).
- **Что логировать**:
  - **Взаимодействие с пользователями**:
    - Входящие сообщения от пользователей (команды и текстовые запросы) с указанием `telegram_id`, `chat_id`, username (уровень INFO). Тексты пользовательских сообщений отключены по умолчанию и включаются отдельной настройкой в конфигурации.
    - Ответы бота пользователям (уровень INFO).
    - Отклонённые запросы (пользователи вне белого списка, некорректные команды) (уровень WARNING).
  - **Операции с данными**:
    - Загрузка документа из Google Docs администратором (уровень INFO).
    - Обновление кэша документа при импорте (уровень INFO).
    - Векторизация разделов при импорте (уровень INFO).
    - Проверка наличия embedding-модели и документа при старте (уровень INFO/WARNING).
    - Ошибки при работе с документом (уровень ERROR).
  - **Бизнес-операции**:
    - Результаты поиска (найдено/не найдено, количество результатов) (уровень INFO).
    - Критические ошибки обработки запросов (уровень ERROR).
- **Аудит**: отдельный файл `logs/audit.log` для журнала действий (как описано в модели данных), без ротации или с отдельной ротацией.

## Подход к обработке ошибок

Обработка ошибок в первом релизе строится на простых принципах: логирование всех ошибок и возврат понятных сообщений пользователю без чувствительных данных.

- **Простые try/except блоки**: используем стандартную обработку исключений Python без сложных механизмов.
- **Логирование всех ошибок**: каждая ошибка логируется с уровнем `ERROR` и контекстом (что произошло, где, с какими данными).
- **Понятные сообщения пользователю**: возвращаем короткие, понятные сообщения без технических деталей и чувствительных данных. Технические детали не раскрываются пользователю.
- **Никаких сложных retry**: в MVP не используем автоматические повторы и сложные стратегии обработки ошибок.

**Типы обрабатываемых ошибок:**
- Проблемы с файлами: файл не найден, проблемы с доступом, некорректный формат JSON/Markdown.
- Некорректные данные: неправильный формат команды, отсутствующие обязательные поля, невалидные значения.
- Сетевые ошибки Telegram API: проблемы с подключением, таймауты, ошибки API.
- Ошибки доступа к Google Docs: недоступность документа, проблемы с импортом.

