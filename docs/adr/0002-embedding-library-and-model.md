# ADR-0002: Выбор библиотеки и модели для embedding

## Статус
Принято

## Контекст
После принятия решения об использовании семантического поиска через embedding-модели (ADR-0001) необходимо выбрать конкретную библиотеку и модель.

Требования:
- Мультиязычность (русский и английский)
- Легковесность (работа на CPU, небольшой размер)
- Простота использования
- Автономность (работа без интернета после загрузки)

## Решение

### Библиотека: `sentence-transformers`
- **Почему**: простая обертка над PyTorch/HuggingFace, встроенная утилита `util.semantic_search`
- **Альтернативы**: прямой PyTorch (слишком низкоуровнево), transformers (требует больше кода)

### Модель: `paraphrase-multilingual-MiniLM-L12-v2` или `multilingual-e5-small`
- **Размер**: ~400-500 МБ
- **Размерность вектора**: 384 для MiniLM, 384 для e5-small
- **Скорость**: десятки тысяч слов/сек на CPU
- **Качество**: хорошее качество для мультиязычного поиска

**Рекомендация**: начать с `paraphrase-multilingual-MiniLM-L12-v2`, при необходимости можно переключиться на `multilingual-e5-small`.

## Последствия

### Положительные
- ✅ Простота использования через `sentence-transformers`
- ✅ Хорошее качество для мультиязычного поиска
- ✅ Приемлемый размер и скорость для MVP

### Отрицательные
- ❌ Требуется PyTorch как зависимость (~500 МБ)
- ❌ Первая загрузка модели требует интернета (решается локальным хранением)

## Альтернативы

### Отклонено: Более крупные модели (например, `multilingual-e5-base`)
- **Почему**: избыточно для Small Data, медленнее, больше размер

### Отклонено: Специализированные модели для русского языка
- **Почему**: требуется поддержка английского языка (IT-термины)

## Связанные решения
- [ADR-0001: Использование семантического поиска](./0001-semantic-search-via-embeddings.md)
- [ADR-0003: Локальное хранение моделей](./0003-local-model-storage.md)

## Дата
2026-01-16
