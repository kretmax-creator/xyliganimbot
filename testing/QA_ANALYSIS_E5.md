# Анализ результатов тестирования модели E5 и рекомендации

**Дата анализа:** 26.01.2026  
**Аналитик:** QA анализ результатов ручного тестирования  
**Версия:** Итерация 8.1 (модель intfloat/multilingual-e5-small)

---

## 1. Статистика тестирования

### Общие показатели

**Текущее тестирование (E5):**
- Всего тесткейсов: 50
- Пройдено успешно (PASS): 39 (78%)
- Провалено (FAIL): 8 (16%)
- С предупреждениями (WARNING): 3 (6%)

**Предыдущее тестирование (MiniLM):**
- Пройдено успешно (PASS): 32 (64%)
- Провалено (FAIL): 7 (14%)
- С предупреждениями (WARNING): 12 (24%)

### Улучшения

✅ **Улучшение качества поиска:**
- Scores значительно повысились: с 0.3-0.5 до 0.8-0.9+
- Улучшение на 14% по прохождению тестов (78% vs 64%)
- Уменьшение количества WARNING с 24% до 6%

✅ **Исправленные проблемы:**
- TC-1.1.3 (сменить заводской PIN) - теперь PASS (было FAIL)
- TC-1.3.3 (ВПН) - теперь PASS (было FAIL)
- TC-1.5.3 (запрос только с символами) - теперь PASS (было FAIL)
- TC-2.1.1 (HTML-форматирование) - теперь PASS (было WARNING)

---

## 2. Анализ проблемных тесткейсов

### Критические проблемы (FAIL)

#### 2.1. Проблема: Модель E5 завышает scores для всех запросов

**Затронутые тесткейсы:**
- TC-1.4.2: "абсолютно нерелевантный запрос xyz123" → score 81.7%
- TC-1.5.2: "как приготовить пиццу" → score ~80%+
- TC-2.2.2: "вфапфвапфпавапф" → все результаты > 80%

**Корневая причина:**
Модель E5 имеет тенденцию возвращать высокие scores (0.8+) даже для нерелевантных запросов. Это связано с тем, что:
1. E5 оптимизирована для понимания семантики, но не различает "релевантно" vs "нерелевантно" для конкретной базы знаний
2. Порог min_score=0.25 слишком низкий для модели E5
3. Нет дополнительной фильтрации на основе абсолютного порога релевантности

**Влияние:**
- Пользователи получают нерелевантные результаты
- Нет возможности отличить хорошие результаты от плохих
- Предупреждение о низкой уверенности не срабатывает

---

#### 2.2. Проблема: Отсутствие обработки отрицаний

**Затронутые тесткейсы:**
- TC-1.2.2: "настройка VPN, но не Иннотех" → первый результат "4.3 VPN ГК Иннотех"

**Корневая причина:**
Семантический поиск через embeddings не понимает отрицания. Модель ищет по ключевым словам "VPN" и "Иннотех" и находит раздел, который содержит оба термина.

**Влияние:**
- Пользователи не могут исключить нежелательные результаты
- Ограничивает возможности поиска

---

#### 2.3. Проблема: Неправильное ранжирование для точных фактов

**Затронутые тесткейсы:**
- TC-1.8.4: "Кому писать по проблемам с DLP?" → раздел "9. Поддержка" только на 3 месте

**Корневая причина:**
Семантический поиск ранжирует по общему смыслу, а не по точному совпадению ключевых слов. Раздел "3.3 Установка обязательного ПО" содержит "DLP" и имеет более высокий score, чем раздел "9. Поддержка" с контактами.

**Влияние:**
- Пользователи не сразу находят нужную информацию
- Требуется прокрутка результатов

---

#### 2.4. Проблема: Отсутствие обработки пустых запросов

**Затронутые тесткейсы:**
- TC-1.5.1: Пустой запрос не обрабатывается

**Корневая причина:**
Telegram не позволяет отправить пустое сообщение, но бот должен проверять пустые строки после обработки.

**Влияние:**
- Низкий приоритет (невозможно проверить в Telegram)

---

#### 2.5. Проблема: Отсутствие обработки ошибок при отсутствии embeddings

**Затронутые тесткейсы:**
- TC-2.4.3: При отсутствии `knowledge_cache.json` бот продолжает работать

**Корневая причина:**
Бот использует fallback на token-based поиск или работает с пустым индексом, но не сообщает пользователю об ошибке.

**Влияние:**
- Пользователи не понимают, что данные не загружены
- Может привести к неправильным результатам

---

#### 2.6. Проблема: Нерелевантные результаты для запросов вне контекста

**Затронутые тесткейсы:**
- TC-1.9.4: "Можно отправить письмо на яндекс почту?" → нерелевантные результаты

**Корневая причина:**
База знаний не содержит информации о запрете отправки на яндекс почту, но бот все равно возвращает результаты с высоким score.

**Влияние:**
- Пользователи получают вводящую в заблуждение информацию

---

### Предупреждения (WARNING)

#### 2.7. Недостаточное покрытие тестами

**Затронутые тесткейсы:**
- TC-2.1.4: Не найден пример с множественными пустыми строками
- TC-2.3.1: Не найден запрос, возвращающий сообщение > 4096 символов
- TC-2.3.2: Не проверено форматирование при разбиении

**Корневая причина:**
Тесткейсы требуют специфических условий, которые сложно воспроизвести вручную.

**Влияние:**
- Низкий приоритет
- Требуется автоматизированное тестирование

---

## 3. Рекомендации по улучшению тестирования

### 3.1. Метрики качества поиска

**Проблема:** Отсутствуют количественные метрики для оценки качества поиска.

**Рекомендации:**

1. **Ввести метрики качества:**
   - Precision@K (точность первых K результатов)
   - Mean Reciprocal Rank (MRR) - средний обратный ранг первого релевантного результата
   - Normalized Discounted Cumulative Gain (NDCG) - учитывает порядок результатов

2. **Создать золотой стандарт (ground truth):**
   - Для каждого тесткейса определить ожидаемые разделы и их порядок
   - Разметить релевантность разделов (релевантно/нерелевантно)
   - Определить минимальный ожидаемый score для каждого типа запроса

3. **Автоматизировать оценку:**
   - Создать скрипт для автоматической проверки результатов поиска
   - Сравнивать результаты с золотым стандартом
   - Генерировать отчеты с метриками

---

### 3.2. Улучшение тесткейсов

**Проблема:** Некоторые тесткейсы не имеют четких критериев успеха.

**Рекомендации:**

1. **Добавить четкие критерии для каждого тесткейса:**
   - Минимальный ожидаемый score
   - Ожидаемые разделы в топ-3
   - Максимально допустимый score для нерелевантных результатов

2. **Создать категории тесткейсов:**
   - **Критичные** - должны проходить всегда (базовая функциональность)
   - **Важные** - должны проходить в большинстве случаев (улучшения UX)
   - **Желательные** - могут не проходить (продвинутые функции)

3. **Добавить негативные тесткейсы:**
   - Запросы, которые НЕ должны возвращать результаты
   - Запросы, которые должны возвращать пустой список
   - Запросы вне контекста базы знаний

---

### 3.3. Автоматизация тестирования

**Проблема:** Ручное тестирование занимает много времени и не воспроизводимо.

**Рекомендации:**

1. **Создать автоматизированные тесты:**
   - Unit-тесты для функций поиска
   - Integration-тесты для полного цикла поиска
   - Regression-тесты для проверки регрессий после изменений

2. **Использовать тестовые данные:**
   - Создать тестовую базу знаний с известными разделами
   - Генерировать тестовые запросы автоматически
   - Проверять результаты автоматически

3. **Непрерывное тестирование:**
   - Запускать автоматические тесты при каждом изменении кода
   - Сравнивать метрики качества между версиями
   - Отслеживать деградацию качества

---

### 3.4. Улучшение процесса тестирования

**Проблема:** Результаты тестирования не структурированы для анализа.

**Рекомендации:**

1. **Структурировать результаты:**
   - Использовать единый формат для всех результатов
   - Добавить метаданные (время выполнения, версия модели, окружение)
   - Сохранять скриншоты для визуальной проверки

2. **Сравнительный анализ:**
   - Сравнивать результаты между версиями моделей
   - Отслеживать тренды улучшения/ухудшения
   - Выявлять паттерны в проблемных тесткейсах

3. **Документирование:**
   - Фиксировать причины провалов тестов
   - Записывать решения проблем
   - Обновлять тесткейсы на основе результатов

---

## 4. Решения проблем

### 4.1. Решение проблемы завышенных scores (Приоритет: ВЫСОКИЙ)

**Проблема:** Модель E5 возвращает высокие scores даже для нерелевантных запросов.

**Решения:**

#### Решение 1: Адаптивный порог min_score

**Описание:**
Использовать динамический порог min_score в зависимости от максимального score в результатах.

**Реализация:**
```python
def adaptive_min_score(results: List[Dict], base_min_score: float = 0.25) -> float:
    """
    Вычисляет адаптивный порог min_score на основе распределения scores.
    
    Если максимальный score низкий (< 0.5), то все результаты нерелевантны.
    Если максимальный score высокий (> 0.9), можно использовать более высокий порог.
    """
    if not results:
        return base_min_score
    
    max_score = max(r['score'] for r in results)
    
    # Если максимальный score низкий, все результаты нерелевантны
    if max_score < 0.5:
        return 1.0  # Отфильтровать все
    
    # Если максимальный score очень высокий, использовать более высокий порог
    if max_score > 0.9:
        return max(0.4, base_min_score)
    
    # Иначе использовать базовый порог
    return base_min_score
```

**Плюсы:**
- Автоматически адаптируется к качеству результатов
- Не требует ручной настройки для каждого запроса

**Минусы:**
- Может отфильтровать релевантные результаты при низком качестве базы знаний

---

#### Решение 2: Абсолютный порог для первого результата

**Описание:**
Если первый результат имеет score ниже определенного порога (например, 0.6), возвращать пустой список.

**Реализация:**
```python
def filter_low_confidence_results(results: List[Dict], 
                                   min_first_score: float = 0.6) -> List[Dict]:
    """
    Фильтрует результаты, если первый результат имеет низкий score.
    """
    if not results:
        return []
    
    if results[0]['score'] < min_first_score:
        return []  # Все результаты нерелевантны
    
    return results
```

**Плюсы:**
- Простая реализация
- Эффективно отфильтровывает нерелевантные запросы

**Минусы:**
- Может быть слишком строгим для некоторых запросов

---

#### Решение 3: Комбинированный подход (РЕКОМЕНДУЕТСЯ)

**Описание:**
Использовать комбинацию адаптивного порога и абсолютного порога для первого результата.

**Реализация:**
```python
def filter_results(results: List[Dict], 
                   base_min_score: float = 0.25,
                   min_first_score: float = 0.6) -> List[Dict]:
    """
    Комбинированный фильтр результатов.
    """
    if not results:
        return []
    
    # Проверка абсолютного порога для первого результата
    if results[0]['score'] < min_first_score:
        return []
    
    # Применение адаптивного порога
    adaptive_threshold = adaptive_min_score(results, base_min_score)
    
    filtered = [r for r in results if r['score'] >= adaptive_threshold]
    
    return filtered
```

**Плюсы:**
- Комбинирует преимущества обоих подходов
- Более гибкий и точный

**Минусы:**
- Требует настройки параметров

---

### 4.2. Решение проблемы отрицаний (Приоритет: СРЕДНИЙ)

**Проблема:** Семантический поиск не понимает отрицания.

**Решения:**

#### Решение 1: Предобработка запросов с отрицаниями

**Описание:**
Распознавать отрицания в запросах и исключать соответствующие разделы из результатов.

**Реализация:**
```python
def preprocess_negation_query(query: str) -> Tuple[str, List[str]]:
    """
    Обрабатывает запросы с отрицаниями.
    
    Возвращает:
    - Очищенный запрос (без отрицаний)
    - Список исключаемых терминов
    """
    exclusion_patterns = [
        r'но не\s+(\w+)',
        r'исключая\s+(\w+)',
        r'без\s+(\w+)',
        r'кроме\s+(\w+)',
    ]
    
    excluded_terms = []
    cleaned_query = query
    
    for pattern in exclusion_patterns:
        matches = re.findall(pattern, query, re.IGNORECASE)
        excluded_terms.extend(matches)
        cleaned_query = re.sub(pattern, '', cleaned_query, flags=re.IGNORECASE)
    
    return cleaned_query.strip(), excluded_terms

def filter_excluded_sections(results: List[Dict], 
                             excluded_terms: List[str]) -> List[Dict]:
    """
    Фильтрует результаты, содержащие исключаемые термины.
    """
    if not excluded_terms:
        return results
    
    filtered = []
    for result in results:
        section_title = result.get('section_title', '').lower()
        section_text = result.get('text', '').lower()
        
        # Проверяем, содержит ли раздел исключаемые термины
        contains_excluded = any(
            term.lower() in section_title or term.lower() in section_text
            for term in excluded_terms
        )
        
        if not contains_excluded:
            filtered.append(result)
    
    return filtered
```

**Плюсы:**
- Решает проблему отрицаний
- Не требует изменений в модели

**Минусы:**
- Работает только для простых случаев
- Может неправильно обработать сложные отрицания

---

#### Решение 2: Постобработка результатов

**Описание:**
После получения результатов проверять наличие исключаемых терминов и понижать их ранг.

**Реализация:**
```python
def rerank_with_exclusions(results: List[Dict], 
                           excluded_terms: List[str]) -> List[Dict]:
    """
    Переранжирует результаты, понижая ранг разделов с исключаемыми терминами.
    """
    if not excluded_terms:
        return results
    
    reranked = []
    excluded = []
    
    for result in results:
        section_title = result.get('section_title', '').lower()
        section_text = result.get('text', '').lower()
        
        contains_excluded = any(
            term.lower() in section_title or term.lower() in section_text
            for term in excluded_terms
        )
        
        if contains_excluded:
            excluded.append(result)
        else:
            reranked.append(result)
    
    # Добавляем исключенные в конец с пониженным score
    for result in excluded:
        result['score'] = result['score'] * 0.5  # Понижаем score
        reranked.append(result)
    
    return reranked
```

**Плюсы:**
- Сохраняет все результаты, но переранжирует их
- Более мягкий подход

**Минусы:**
- Исключаемые разделы все еще могут быть в результатах

---

### 4.3. Решение проблемы ранжирования для точных фактов (Приоритет: СРЕДНИЙ)

**Проблема:** Разделы с точными фактами (контакты, адреса) не всегда на первом месте.

**Решения:**

#### Решение 1: Boost для разделов с точными совпадениями

**Описание:**
Повышать score разделов, которые содержат точные совпадения ключевых слов из запроса.

**Реализация:**
```python
def boost_exact_matches(results: List[Dict], 
                        query: str, 
                        boost_factor: float = 1.2) -> List[Dict]:
    """
    Повышает score разделов с точными совпадениями ключевых слов.
    """
    query_words = set(preprocess_query(query).lower().split())
    
    for result in results:
        section_title = result.get('section_title', '').lower()
        section_text = result.get('text', '').lower()
        
        # Подсчитываем точные совпадения в заголовке
        title_matches = sum(1 for word in query_words if word in section_title)
        # Подсчитываем точные совпадения в тексте
        text_matches = sum(1 for word in query_words if word in section_text)
        
        # Boost зависит от количества совпадений
        matches = title_matches * 2 + text_matches  # Заголовок важнее
        
        if matches > 0:
            boost = 1.0 + (matches * 0.1 * boost_factor)
            result['score'] = min(1.0, result['score'] * boost)
    
    # Пересортировываем результаты
    results.sort(key=lambda x: x['score'], reverse=True)
    
    return results
```

**Плюсы:**
- Улучшает ранжирование для точных фактов
- Не требует изменений в модели

**Минусы:**
- Требует настройки boost_factor

---

#### Решение 2: Отдельный поиск для точных фактов

**Описание:**
Использовать гибридный подход: семантический поиск + keyword-based поиск для точных фактов.

**Реализация:**
```python
def hybrid_search(query: str, 
                  embeddings_data: Dict,
                  model: SentenceTransformer,
                  exact_match_keywords: List[str] = None) -> List[Dict]:
    """
    Гибридный поиск: семантический + keyword-based для точных фактов.
    """
    # Семантический поиск
    semantic_results = semantic_search(query, embeddings_data, model)
    
    # Если запрос содержит ключевые слова для точных фактов, используем boost
    if exact_match_keywords:
        for keyword in exact_match_keywords:
            if keyword.lower() in query.lower():
                semantic_results = boost_exact_matches(
                    semantic_results, 
                    query, 
                    boost_factor=1.5
                )
    
    return semantic_results
```

**Плюсы:**
- Более точное ранжирование для точных фактов
- Гибридный подход

**Минусы:**
- Более сложная реализация

---

### 4.4. Решение проблемы обработки ошибок (Приоритет: ВЫСОКИЙ)

**Проблема:** Бот не сообщает пользователю об отсутствии embeddings.

**Решения:**

#### Решение 1: Улучшить проверки при старте

**Описание:**
Проверять наличие всех необходимых компонентов при старте и логировать предупреждения.

**Реализация:**
```python
def check_system_health() -> Dict[str, bool]:
    """
    Проверяет состояние системы при старте.
    """
    health = {
        'model_available': False,
        'embeddings_available': False,
        'document_available': False,
    }
    
    # Проверка модели
    model = load_embedding_model()
    health['model_available'] = model is not None
    
    # Проверка embeddings
    cache_file = Path("data/knowledge_cache.json")
    embeddings_data = load_embeddings_from_cache(cache_file)
    health['embeddings_available'] = embeddings_data is not None
    
    # Проверка документа
    markdown_file = Path("data/knowledge.md")
    health['document_available'] = markdown_file.exists()
    
    return health
```

---

#### Решение 2: Улучшить сообщения об ошибках пользователю

**Описание:**
Добавить понятные сообщения об ошибках при отсутствии компонентов.

**Реализация:**
```python
async def handle_search_query(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    Обработчик поисковых запросов с улучшенной обработкой ошибок.
    """
    # Проверка наличия embeddings
    if not search_index or "embeddings" not in search_index:
        await message.reply_text(
            "⚠️ База знаний не индексирована. "
            "Обратитесь к администратору для выполнения команды /admin vectorize."
        )
        return
    
    # Проверка наличия модели
    model = load_embedding_model()
    if model is None:
        await message.reply_text(
            "⚠️ Модель поиска не загружена. "
            "Обратитесь к администратору для выполнения команды /admin load_model."
        )
        return
    
    # Выполнение поиска
    # ...
```

---

### 4.5. Решение проблемы нерелевантных результатов вне контекста (Приоритет: СРЕДНИЙ)

**Проблема:** Бот возвращает результаты даже для запросов вне контекста базы знаний.

**Решения:**

#### Решение 1: Проверка релевантности через порог

**Описание:**
Использовать более высокий порог min_score и проверять, превышает ли максимальный score определенный порог.

**Реализация:**
```python
def filter_out_of_context_results(results: List[Dict],
                                   min_confidence: float = 0.7) -> List[Dict]:
    """
    Фильтрует результаты, если максимальный score ниже порога уверенности.
    """
    if not results:
        return []
    
    max_score = max(r['score'] for r in results)
    
    if max_score < min_confidence:
        return []  # Все результаты нерелевантны
    
    return results
```

---

#### Решение 2: Детекция запросов вне контекста

**Описание:**
Использовать отдельную модель или эвристики для определения, относится ли запрос к контексту базы знаний.

**Реализация:**
```python
def is_query_in_context(query: str, 
                        results: List[Dict],
                        min_score_threshold: float = 0.7) -> bool:
    """
    Определяет, относится ли запрос к контексту базы знаний.
    """
    if not results:
        return False
    
    max_score = max(r['score'] for r in results)
    
    # Если максимальный score низкий, запрос вне контекста
    if max_score < min_score_threshold:
        return False
    
    # Дополнительная проверка: есть ли хотя бы один результат с высоким score
    high_score_results = [r for r in results if r['score'] >= min_score_threshold]
    
    return len(high_score_results) > 0
```

---

## 5. План действий

### Фаза 1: Критические исправления (1-2 дня)

1. **Реализовать адаптивный порог min_score**
   - Файл: `src/search.py`
   - Функция: `semantic_search()`
   - Тестирование: TC-1.4.2, TC-1.5.2, TC-2.2.2

2. **Улучшить обработку ошибок**
   - Файл: `src/handlers/messages.py`
   - Функция: `handle_search_query()`
   - Тестирование: TC-2.4.3

3. **Добавить проверку пустых запросов**
   - Файл: `src/handlers/messages.py`
   - Тестирование: TC-1.5.1

---

### Фаза 2: Улучшения качества поиска (2-3 дня)

4. **Реализовать обработку отрицаний**
   - Файл: `src/search.py`
   - Функция: `preprocess_query()` + фильтрация результатов
   - Тестирование: TC-1.2.2

5. **Добавить boost для точных совпадений**
   - Файл: `src/search.py`
   - Функция: `boost_exact_matches()`
   - Тестирование: TC-1.8.4

6. **Улучшить фильтрацию нерелевантных запросов**
   - Файл: `src/search.py`
   - Функция: `filter_out_of_context_results()`
   - Тестирование: TC-1.9.4

---

### Фаза 3: Улучшение тестирования (3-5 дней)

7. **Создать автоматизированные тесты**
   - Файл: `test_search_quality.py`
   - Метрики: Precision@K, MRR, NDCG

8. **Создать золотой стандарт**
   - Файл: `data/test_ground_truth.json`
   - Разметка релевантности для каждого тесткейса

9. **Улучшить тесткейсы**
   - Файл: `docs/TEST_PLAN.md`
   - Добавить четкие критерии успеха

---

## 6. Метрики успеха

### Критерии приемки для Фазы 1:

- ✅ TC-1.4.2: Нерелевантные запросы возвращают 0 результатов или пустой список
- ✅ TC-1.5.2: Запросы вне контекста возвращают пустой список
- ✅ TC-2.2.2: Предупреждение о низкой уверенности срабатывает для нерелевантных запросов
- ✅ TC-2.4.3: При отсутствии embeddings пользователь получает понятное сообщение

### Критерии приемки для Фазы 2:

- ✅ TC-1.2.2: Запросы с отрицаниями корректно исключают нежелательные результаты
- ✅ TC-1.8.4: Разделы с точными фактами (контакты) находятся в топ-2
- ✅ TC-1.9.4: Запросы вне контекста возвращают пустой список

### Общие метрики:

- **Прохождение тестов:** > 90% (сейчас 78%)
- **Средний score релевантных результатов:** > 0.85
- **Средний score нерелевантных результатов:** < 0.5 (или пустой список)

---

## 7. Заключение

Модель E5 значительно улучшила качество поиска по сравнению с предыдущей моделью:
- Scores повысились с 0.3-0.5 до 0.8-0.9+
- Прохождение тестов улучшилось с 64% до 78%

Однако остаются проблемы:
- Завышенные scores для нерелевантных запросов
- Отсутствие обработки отрицаний
- Неправильное ранжирование для точных фактов

Предложенные решения позволят:
- Улучшить качество поиска до 90%+ прохождения тестов
- Снизить количество ложных срабатываний
- Улучшить пользовательский опыт

Рекомендуется начать с Фазы 1 (критические исправления), так как они решают наиболее важные проблемы и могут быть реализованы быстро.
