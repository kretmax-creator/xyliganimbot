"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è xyliganimbot.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–∞–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
–∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏ –æ—Ç–ø—Ä–∞–≤–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
"""

from pathlib import Path
from typing import Dict, Any, List, Optional

from telegram import Update
from telegram.ext import ContextTypes

from src.search import search
from src.logging import get_logger

logger = get_logger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—É—Ç–µ–π –∏ –∏–Ω–¥–µ–∫—Å–∞
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞
search_index: Optional[Dict[str, Any]] = None
markdown_file_path: Optional[Path] = None
images_dir_path: Optional[Path] = None


def escape_html(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã HTML –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram.

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è

    Returns:
        –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ HTML-—Å–∏–º–≤–æ–ª—ã
    text = text.replace('&', '&amp;')
    text = text.replace('<', '&lt;')
    text = text.replace('>', '&gt;')
    return text


def init_search_context(
    index: Dict[str, Any],
    markdown_file: Path,
    images_dir: Path,
) -> None:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–∏—Å–∫–∞.

    Args:
        index: –ü–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
        markdown_file: –ü—É—Ç—å –∫ Markdown-—Ñ–∞–π–ª—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º (–∏–ª–∏ HTML –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        images_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    """
    global search_index, markdown_file_path, images_dir_path
    
    search_index = index
    markdown_file_path = markdown_file
    images_dir_path = images_dir
    
    logger.info(f"Search context initialized:")
    logger.info(f"  Markdown/HTML file: {markdown_file}")
    logger.info(f"  Images dir: {images_dir}")
    logger.info(f"  Index type: {'embeddings' if 'embeddings' in index else 'token-based'}")


def format_search_results(results: List[Dict[str, Any]], max_text_length: int = 1000) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å HTML-—Ä–∞–∑–º–µ—Ç–∫–æ–π.

    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        max_text_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–¥–µ–ª–∞ –≤ –æ—Ç–≤–µ—Ç–µ

    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ HTML
    """
    if not results:
        return "‚ùå –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –∑–∞–ø—Ä–æ—Å–∞."

    message_parts = [f"üîç –ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(results)}"]

    for i, result in enumerate(results, 1):
        section_title = result.get("section_title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
        text = result.get("text", "")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º score (–¥–ª—è semantic search) –∏–ª–∏ relevance_score (–¥–ª—è token-based)
        score = result.get("score", result.get("relevance_score", 0))
        
        # –ï—Å–ª–∏ score < 0.3, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence_warning = ""
        if isinstance(score, float) and score < 0.3:
            confidence_warning = " ‚ö†Ô∏è (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"

        # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
        if text and len(text) > max_text_length:
            text = text[:max_text_length] + "..."

        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ç–µ–∫—Å—Ç –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ HTML
        escaped_title = escape_html(section_title)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º score –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if isinstance(score, float):
            score_text = f" (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.1%})"
        else:
            score_text = f" (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score})"
        
        message_parts.append(f"\nüìå <b>{escaped_title}</b>{escape_html(score_text)}{confidence_warning}")
        
        if text:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è HTML –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            escaped_text = escape_html(text.strip())
            # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ
            escaped_text = "\n".join(line.strip() for line in escaped_text.split("\n") if line.strip())
            message_parts.append(f"\n{escaped_text}")
        else:
            message_parts.append("\n(–¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")

        if i < len(results):
            message_parts.append("\n" + "‚îÄ" * 30)

    return "\n".join(message_parts)


async def send_search_response(
    update: Update,
    results: List[Dict[str, Any]],
    max_images: int = 3,
) -> None:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

    Args:
        update: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç Telegram
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        max_images: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (–æ—Ç–∫–ª—é—á–µ–Ω–æ)
    """
    if not update.message:
        logger.warning("Cannot send search response: no message in update")
        return

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
    text_response = format_search_results(results)

    # Telegram –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: 4096 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
    MAX_MESSAGE_LENGTH = 4096

    try:
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
        if len(text_response) > MAX_MESSAGE_LENGTH:
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º (–ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é)
            separator = "\n" + "‚îÄ" * 30
            sections = text_response.split(separator)
            
            parts = []
            current_part = sections[0] if sections else ""
            
            for i, section in enumerate(sections[1:], 1):
                section_with_separator = separator + section
                
                # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç
                if len(current_part) + len(section_with_separator) > MAX_MESSAGE_LENGTH - 100:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å
                    if current_part:
                        parts.append(current_part)
                    current_part = section_with_separator.lstrip(separator)
                else:
                    current_part += section_with_separator
            
            if current_part:
                parts.append(current_part)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
            for i, part in enumerate(parts):
                if i == 0:
                    # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - –∫–∞–∫ –æ—Ç–≤–µ—Ç
                    await update.message.reply_text(part, parse_mode="HTML")
                else:
                    # –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è - –æ–±—ã—á–Ω—ã–µ
                    await update.message.chat.send_message(part, parse_mode="HTML")
                logger.info(f"Search response part {i+1}/{len(parts)} sent ({len(part)} chars)")
        else:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
            await update.message.reply_text(text_response, parse_mode="HTML")
            logger.info(f"Search response sent: {len(results)} results ({len(text_response)} chars)")

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç–∫–ª—é—á–µ–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    except Exception as e:
        logger.error(f"Error sending search response: {e}", exc_info=True)
        try:
            # Fallback: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            await update.message.reply_text(
                "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            )
        except Exception as e2:
            logger.error(f"Error sending error message: {e2}", exc_info=True)


async def handle_search_query(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∫–∞–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

    Args:
        update: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç Telegram
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
    """
    user = update.effective_user
    chat = update.effective_chat
    message = update.message

    if not user or not chat or not message:
        logger.warning("Received message without user, chat or message")
        return

    query = message.text
    if not query or not query.strip():
        logger.debug("Empty query received")
        try:
            await message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.")
        except Exception as e:
            logger.error(f"Error sending empty-query message: {e}")
        return

    logger.info(
        f"Search query from user_id={user.id}, username={user.username}, "
        f"query='{query[:50]}...'"
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    from pathlib import Path
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ (Markdown –∏–ª–∏ HTML –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    if not markdown_file_path or not markdown_file_path.exists():
        logger.warning("Markdown/HTML file not found")
        try:
            await message.reply_text(
                "–î–æ–∫—É–º–µ–Ω—Ç –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω. "
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."
            )
        except Exception as e:
            logger.error(f"Error sending error message: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∏ embeddings
    has_embeddings = (
        isinstance(search_index, dict)
        and search_index.get("embeddings") is not None
        and len(search_index.get("embeddings", [])) > 0
    )
    has_token_index = isinstance(search_index, dict) and (
        bool(search_index.get("section_index")) or bool(search_index.get("content_index"))
    )

    if not search_index or (not has_embeddings and not has_token_index):
        logger.warning("Search index missing or embeddings not loaded")
        try:
            await message.reply_text(
                "‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞. "
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã /admin vectorize."
            )
        except Exception as e:
            logger.error(f"Error sending error message: {e}")
        return

    # –î–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
    if has_embeddings:
        from src.search import load_embedding_model
        model = load_embedding_model()
        if model is None:
            logger.warning("Embedding model not available")
            try:
                await message.reply_text(
                    "‚ö†Ô∏è –ú–æ–¥–µ–ª—å –ø–æ–∏—Å–∫–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. "
                    "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã /admin load_model."
                )
            except Exception as e:
                logger.error(f"Error sending error message: {e}")
            return

    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    try:
        results = search(
            query=query,
            index=search_index,
            markdown_file=markdown_file_path,
            limit=5,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
        )

        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å score
        if results:
            scores = [r.get("score", r.get("relevance_score", 0)) for r in results]
            scores_str = ", ".join([f"{s:.3f}" if isinstance(s, float) else str(s) for s in scores[:3]])
            logger.info(
                f"Search completed: {len(results)} results found "
                f"(scores: [{scores_str}])"
            )
        else:
            logger.info("Search completed: no results found")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        await send_search_response(update, results)

    except Exception as e:
        logger.error(f"Error processing search query: {e}", exc_info=True)
        try:
            await message.reply_text(
                "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            )
        except Exception as e2:
            logger.error(f"Error sending error message: {e2}", exc_info=True)
