"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è xyliganimbot.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–∞–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
–∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏ –æ—Ç–ø—Ä–∞–≤–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
"""

from pathlib import Path
from typing import Dict, Any, List, Optional

from telegram import Update
from telegram.ext import ContextTypes

from src.search import search
from src.logging import get_logger

logger = get_logger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—É—Ç–µ–π –∏ –∏–Ω–¥–µ–∫—Å–∞
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞
search_index: Optional[Dict[str, Any]] = None
html_file_path: Optional[Path] = None
sections_file_path: Optional[Path] = None
images_dir_path: Optional[Path] = None


def escape_markdown(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Markdown –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram.

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è

    Returns:
        –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    # –°–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –≤ Markdown
    special_chars = ['*', '_', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    for char in special_chars:
        text = text.replace(char, '\\' + char)
    return text


def init_search_context(
    index: Dict[str, Any],
    html_file: Path,
    sections_file: Path,
    images_dir: Path,
) -> None:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–∏—Å–∫–∞.

    Args:
        index: –ü–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
        html_file: –ü—É—Ç—å –∫ HTML-—Ñ–∞–π–ª—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
        sections_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ —Ä–∞–∑–¥–µ–ª–æ–≤
        images_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    """
    global search_index, html_file_path, sections_file_path, images_dir_path
    search_index = index
    html_file_path = html_file
    sections_file_path = sections_file
    images_dir_path = images_dir
    logger.info("Search context initialized")


def format_search_results(results: List[Dict[str, Any]], max_text_length: int = 1000) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.

    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        max_text_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–¥–µ–ª–∞ –≤ –æ—Ç–≤–µ—Ç–µ

    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    """
    if not results:
        return "‚ùå –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –∑–∞–ø—Ä–æ—Å–∞."

    message_parts = [f"üîç –ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(results)}\n"]

    for i, result in enumerate(results, 1):
        section_title = result.get("section_title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
        text = result.get("text", "")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º score (–¥–ª—è semantic search) –∏–ª–∏ relevance_score (–¥–ª—è token-based)
        score = result.get("score", result.get("relevance_score", 0))
        
        # –ï—Å–ª–∏ score < 0.3, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence_warning = ""
        if isinstance(score, float) and score < 0.3:
            confidence_warning = " ‚ö†Ô∏è (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"

        # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
        if text and len(text) > max_text_length:
            text = text[:max_text_length] + "..."

        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ç–µ–∫—Å—Ç –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ Markdown
        escaped_title = escape_markdown(section_title)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º score –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if isinstance(score, float):
            score_text = f" (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.1%})"
        else:
            score_text = f" (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score})"
        
        message_parts.append(f"\nüìå *{escaped_title}*{score_text}{confidence_warning}")
        
        if text:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ Markdown
            escaped_text = escape_markdown(text)
            message_parts.append(f"\n{escaped_text}")
        else:
            message_parts.append("\n(–¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")

        if i < len(results):
            message_parts.append("\n" + "‚îÄ" * 30)

    return "\n".join(message_parts)


async def send_search_response(
    update: Update,
    results: List[Dict[str, Any]],
    max_images: int = 3,
) -> None:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

    Args:
        update: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç Telegram
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        max_images: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
    """
    if not update.message:
        logger.warning("Cannot send search response: no message in update")
        return

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
    text_response = format_search_results(results)

    # Telegram –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: 4096 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
    MAX_MESSAGE_LENGTH = 4096

    try:
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
        if len(text_response) > MAX_MESSAGE_LENGTH:
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º (–ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é)
            separator = "\n" + "‚îÄ" * 30
            sections = text_response.split(separator)
            
            parts = []
            current_part = sections[0] if sections else ""
            
            for i, section in enumerate(sections[1:], 1):
                section_with_separator = separator + section
                
                # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç
                if len(current_part) + len(section_with_separator) > MAX_MESSAGE_LENGTH - 100:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å
                    if current_part:
                        parts.append(current_part)
                    current_part = section_with_separator.lstrip(separator)
                else:
                    current_part += section_with_separator
            
            if current_part:
                parts.append(current_part)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
            for i, part in enumerate(parts):
                if i == 0:
                    # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - –∫–∞–∫ –æ—Ç–≤–µ—Ç
                    await update.message.reply_text(part, parse_mode="Markdown")
                else:
                    # –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è - –æ–±—ã—á–Ω—ã–µ
                    await update.message.chat.send_message(part, parse_mode="Markdown")
                logger.info(f"Search response part {i+1}/{len(parts)} sent ({len(part)} chars)")
        else:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
            await update.message.reply_text(text_response, parse_mode="Markdown")
            logger.info(f"Search response sent: {len(results)} results ({len(text_response)} chars)")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if images_dir_path and images_dir_path.exists():
            image_files = list(images_dir_path.glob("*.png")) + list(
                images_dir_path.glob("*.jpg")
            ) + list(images_dir_path.glob("*.jpeg"))

            if image_files:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                images_to_send = image_files[:max_images]
                logger.info(f"Sending {len(images_to_send)} images")

                for image_path in images_to_send:
                    try:
                        with open(image_path, "rb") as photo:
                            await update.message.reply_photo(photo=photo)
                    except Exception as e:
                        logger.warning(f"Error sending image {image_path}: {e}")

    except Exception as e:
        logger.error(f"Error sending search response: {e}", exc_info=True)
        try:
            # Fallback: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            await update.message.reply_text(
                "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            )
        except Exception as e2:
            logger.error(f"Error sending error message: {e2}", exc_info=True)


async def handle_search_query(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∫–∞–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

    Args:
        update: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç Telegram
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
    """
    user = update.effective_user
    chat = update.effective_chat
    message = update.message

    if not user or not chat or not message:
        logger.warning("Received message without user, chat or message")
        return

    query = message.text
    if not query or not query.strip():
        logger.debug("Empty query received")
        return

    logger.info(
        f"Search query from user_id={user.id}, username={user.username}, "
        f"query='{query[:50]}...'"
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    from pathlib import Path
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
    if not html_file_path or not html_file_path.exists():
        logger.warning("HTML file not found")
        try:
            await message.reply_text(
                "–î–æ–∫—É–º–µ–Ω—Ç –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω. "
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."
            )
        except Exception as e:
            logger.error(f"Error sending error message: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞ —Å —Ä–∞–∑–¥–µ–ª–∞–º–∏
    if not sections_file_path or not sections_file_path.exists():
        logger.warning("Sections file not found")
        try:
            await message.reply_text(
                "–§–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. "
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
            )
        except Exception as e:
            logger.error(f"Error sending error message: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ª–∏ –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
    if not search_index:
        logger.error("Search index not initialized")
        try:
            await message.reply_text(
                "–ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. "
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
            )
        except Exception as e:
            logger.error(f"Error sending error message: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è embeddings –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
    has_embeddings = isinstance(search_index, dict) and "embeddings" in search_index
    if has_embeddings:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        from src.search import load_embedding_model
        model = load_embedding_model()
        if model is None:
            logger.warning("Embedding model not available, falling back to token-based search")
            # –ú–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å token-based –ø–æ–∏—Å–∫–æ–º, –µ—Å–ª–∏ –µ—Å—Ç—å token-based –∏–Ω–¥–µ–∫—Å
            if "section_index" not in search_index and "content_index" not in search_index:
                try:
                    await message.reply_text(
                        "–ú–æ–¥–µ–ª—å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. "
                        "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏."
                    )
                except Exception as e:
                    logger.error(f"Error sending error message: {e}")
                return

    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    try:
        results = search(
            query=query,
            index=search_index,
            html_file=html_file_path,
            sections_file=sections_file_path,
            limit=5,
        )

        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å score
        if results:
            scores = [r.get("score", r.get("relevance_score", 0)) for r in results]
            scores_str = ", ".join([f"{s:.3f}" if isinstance(s, float) else str(s) for s in scores[:3]])
            logger.info(
                f"Search completed: {len(results)} results found "
                f"(scores: [{scores_str}])"
            )
        else:
            logger.info("Search completed: no results found")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        await send_search_response(update, results)

    except Exception as e:
        logger.error(f"Error processing search query: {e}", exc_info=True)
        try:
            await message.reply_text(
                "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            )
        except Exception as e2:
            logger.error(f"Error sending error message: {e2}", exc_info=True)
